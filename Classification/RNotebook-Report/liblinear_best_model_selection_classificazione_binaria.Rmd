---
title: Best LibLineaR model selection (solo multi-classification con metodi 0-7) -
  Task di classificazione binario 1,2,3
output:
  html_notebook: default
  html_document:
    df_print: paged
  pdf_document: default
---
```{r setup, include=FALSE}
library(knitr)
library(LiblineaR)
library(caret)
require(SparseM)
library(kableExtra)
options(knitr.table.format = "html")

excluded_predictors <- c('ID')
class <- c('cOPE','cCON','cEXT','cAGR','cNEU')

classification <- function(class_num,dataset) {
  excluded_predictors_new <- c(excluded_predictors,class[-class_num])
  d <- dataset[ , !(names(dataset) %in% excluded_predictors_new)]
    
  d <- d[!(d[,class[class_num]]=='n'),]
  d[,class[class_num]] <- factor(d[,class[class_num]])
  
  set.seed(1234)
  trainIndex <- createDataPartition(d[,class[class_num]], p=0.70, list=FALSE)
  data_train <- d[ trainIndex,]
  data_test <- d[-trainIndex,]
    
  x_train <- data_train[, !(names(data_train) %in% class[class_num])]
  y_train <- data_train[,class[class_num]]
  x_test <- data_test[, !(names(data_test) %in% class[class_num])]
  y_test <- data_test[,class[class_num]]
  
  tryTypes=c(0:7)
  tryCosts=c(0.01,0.05,0.10,0.25,0.5,1,2,5,10,50,100)
  bestCost=NA
  bestAcc=0
  bestType=NA
  
  for(ty in tryTypes){
  for(co in tryCosts){
    
    set.seed(1234)
    model <- LiblineaR(data=x_train,target=y_train,type=ty,cost=co,verbose=FALSE)

    predictions <- predict(model, x_test)
    cm <- confusionMatrix(predictions$predictions, y_test, positive = 'H')
    acc <- cm$overall[1]
    
    if(acc>bestAcc){
      bestCost=co
      bestAcc=acc
      bestType=ty
  } } }
  
  set.seed(1234)
  model <- LiblineaR(data=x_train,target=y_train,type=bestType,cost=bestCost,verbose=FALSE)
  
  predictions <- predict(model, x_test)
  cm <- confusionMatrix(predictions$predictions, y_test, positive = 'H')
  
  accuracy <- round(cm$overall[1], digits = 2)
  rmse <- round(RMSE(as.numeric(predictions$predictions),as.numeric(y_test)),2)
  mae <- round(MAE(as.numeric(predictions$predictions),as.numeric(y_test)),2)
  best_param <- paste('Model:',bestType,'C:',bestCost,sep=' ')
  return(c(mae,rmse,accuracy,best_param))
}
```

LiblineaR permette di riprodurre 10 tipi di modelli lineari (generalizzati), andando a combinare diversi tipi di funzioni di perdita e schemi di regolarizzazione. I modelli disponibili per la multi-class classification sono i seguenti:

* 0 – L2-regularized  logistic  regression  (pri-mal)
* 1 – L2-regularized L2-loss support vector classification (dual)
* 2 – L2-regularized L2-loss support vector classification (primal)
* 3 – L2-regularized L1-loss support vector classification (dual)
* 4 – Support vector classification by Crammer and Singer
* 5 – L1-regularized L2-loss support vector classification
* 6 – L1-regularized logistic regression
* 7 – L2-regularized logistic regression (dual)

In questo report sono mostrati i risultati della classificazione con best model selection tra gli 8 modelli appena elencati per i tre task di classificazione binaria.

Per quanto riguarda la classificazione, si è diviso il dataset in training set (70%) e test set (30%). In seguito si è eseguita un fase di tuning volta a stabilire quale sia il modello liblineaR, e il relativo parametro di costo C, per il quale si registra l'accuracy maggiore nel predire i valori del test set. Si è poi ri-addestrato il modello, generando la matrice di confusione con le predizioni sul test set, calcolando poi le metriche di accuracy, MAE e RMSE.

Si riportano di seguito i risultati ottenuti. Sono mostrate tre tabelle: la prima riporta i valori di accuracy, la seconda quelli di MAE e l'ultima di RMSE. In ogni tabella le righe rappresentano i set di feature analizzati, mentre le colonne indicano il tratto di personalità valutato, con l'ultima colonna che riporta la media dei risultati per set di feature.

```{r, include=FALSE, WARNING=FALSE}

get_metrics_df <- function(dataset_list) {
  
  file_num <- 1
  dataset <- readRDS(dataset_list[file_num])
    
  accuracies <- list()
  maes <- list()
  rmses <- list()
  class_num <- 1
  result = classification(class_num,dataset)
  mae <- result[1]
  rmse <- result[2]
  accuracy <- result[3]
  
  class_name <- substr(class[class_num], 2, nchar(class[class_num]))
    print(paste(class_name,'Feature set',file_num,result[4],sep=' '))
  
  accuracies_df <- data.frame("Feature" = c("Mairesse, no NLoN"), 'temp_name' = as.numeric(accuracy), stringsAsFactors = F)
  names(accuracies_df)[names(accuracies_df) == 'temp_name'] <- class_name
  accuracies[class_num] <- as.numeric(accuracy)
  
  mae_df <- data.frame("Feature" = c("Mairesse, no NLoN"), 'temp_name' = as.numeric(mae), stringsAsFactors = F)
  names(mae_df)[names(mae_df) == 'temp_name'] <- class_name
  maes[class_num] <- as.numeric(mae)
    
  rmse_df <- data.frame("Feature" = c("Mairesse, no NLoN"), 'temp_name' = as.numeric(rmse), stringsAsFactors = F)
  names(rmse_df)[names(rmse_df) == 'temp_name'] <- class_name
  rmses[class_num] <- as.numeric(rmse)
    
  for(class_num in 2:5){
    result = classification(class_num,dataset)
    mae <- result[1]
    rmse <- result[2]
    accuracy <- result[3]
  
    class_name <- substr(class[class_num], 2, nchar(class[class_num]))
    print(paste(class_name,'Feature set',file_num,result[4],sep=' '))
    
    accuracies_df <- cbind(accuracies_df,'temp_name'=as.numeric(accuracy))
    names(accuracies_df)[names(accuracies_df) == 'temp_name'] <- class_name
    accuracies[class_num] <- as.numeric(accuracy)
    
    mae_df <- cbind(mae_df,'temp_name'=as.numeric(mae))
    names(mae_df)[names(mae_df) == 'temp_name'] <- class_name
    maes[class_num] <- as.numeric(mae)
    
    rmse_df <- cbind(rmse_df,'temp_name'=as.numeric(rmse))
    names(rmse_df)[names(rmse_df) == 'temp_name'] <- class_name
    rmses[class_num] <- as.numeric(rmse)
    }
    
  accuracies_df <- cbind(accuracies_df,'mean'=mean(as.numeric(accuracies)))
  mae_df <- cbind(mae_df,'mean'=mean(as.numeric(maes)))
  rmse_df <- cbind(rmse_df,'mean'=mean(as.numeric(rmses)))
    
  
  row_names = c('Mairesse, with NLoN',
                'Mairesse+N-grams, no NLoN',
                'Mairesse+N-grams, with NLoN')
  for(file_num in (2:length(dataset_list))){
    dataset <- readRDS(dataset_list[file_num])
    accuracies <- list()
    maes <- list()
    rmses <- list()
    
    class_num <- 1
    result = classification(class_num,dataset)
    mae <- result[1]
    rmse <- result[2]
    accuracy <- result[3]
   
    class_name <- substr(class[class_num], 2, nchar(class[class_num]))
    print(paste(class_name,'Feature set',file_num,result[4],sep=' '))
    
    accuracies_df <- rbind(accuracies_df,list(row_names[file_num-1],0,0,0,0,0,0))
    accuracies_df[file_num,class_name] <- as.numeric(accuracy)
    accuracies[class_num] <- as.numeric(accuracy)
    
    mae_df <- rbind(mae_df,list(row_names[file_num-1],0,0,0,0,0,0))
    mae_df[file_num,class_name] <- as.numeric(mae)
    maes[class_num] <- as.numeric(mae)
      
    rmse_df <- rbind(rmse_df,list(row_names[file_num-1],0,0,0,0,0,0))
    rmse_df[file_num,class_name] <- as.numeric(rmse)
    rmses[class_num] <- as.numeric(rmse)
    
    for(class_num in 2:5){
      result = classification(class_num,dataset)
      mae <- result[1]
      rmse <- result[2]
      accuracy <- result[3]
    
      class_name <- substr(class[class_num], 2, nchar(class[class_num]))
      print(paste(class_name,'Feature set',file_num,result[4],sep=' '))
      
      accuracies_df[file_num,class_name] <- as.numeric(accuracy)
      accuracies[class_num] <- as.numeric(accuracy)
      
      mae_df[file_num,class_name] <- as.numeric(mae)
      maes[class_num] <- as.numeric(mae)
        
      rmse_df[file_num,class_name] <- as.numeric(rmse)
      rmses[class_num] <- as.numeric(rmse)
    }
    accuracies_df[file_num,'mean'] <- mean(as.numeric(accuracies))
    mae_df[file_num,'mean'] <- mean(as.numeric(maes))
    rmse_df[file_num,'mean'] <- mean(as.numeric(rmses))
  }
  result <- list()
  result[[1]] <- accuracies_df
  result[[2]] <- mae_df
  result[[3]] <- rmse_df

  return(result)
}
```

* Best model selection - Task di classificazione binario 1

```{r}
data = c('RObjects/feature_texts_task1.rds',
         'RObjects/feature_texts_nlon_task1.rds',
         'RObjects/feature_texts_task1_ngrams.rds',
         'RObjects/feature_texts_nlon_task1_ngrams.rds')

metrics_df = get_metrics_df(data)

kable(metrics_df[[1]], caption = 'Accuracy con best model selection liblinear task 1')%>%
        kable_styling("striped") %>%
        add_header_above(c(" " = 1, "Accuracy" = 6))

kable(metrics_df[[2]], caption = 'MAE con best model selection liblinear task 1')%>%
        kable_styling("striped") %>%
        add_header_above(c(" " = 1, "MAE" = 6))

kable(metrics_df[[3]], caption = 'RMSE con best model selection liblinear task 1')%>%
        kable_styling("striped") %>%
        add_header_above(c(" " = 1, "RMSE" = 6))
```

Osservando i valori di accuracy per il primo task, mostrati nella tabella \ref{LibRTask1}, si nota come le accuracy medie coi 4 set di feature siano comprese nell'intervallo tra 0.71 e 0.8. Le prestazioni migliori (accuracy pari a 0.804) si registrano utilizzando come set di feature quello composto dalle feature Mairesse con n-grammi senza pre-processing NLoN. Un valore medio leggermente minore è ottenuto usando il set di feature composto dalle feature Mairesse con n-grammi e pre-processing NLoN (accuracy pari a 0.764). Peggiori sono le performance di accuratezza con il set di feature Mairesse senza NLoN (0.714) e con il set di feature Mairesse con pre-processing NLoN (0.75).

Analizzando le accuracy per singolo tratto di personalità, si osserva come con tutti e i 4 set si ottiene un valore di accuracy pari a 0.8 per l'Openness. Per la Conscientiousness i risultati migliori si raggiungono con gli ultimi tre insiemi di feature (accuracy uguale a 0.75), mentre con il primo set il valore equivale a 0.5. Per il tratto dell'Extraversion il set con il quale la classificazione si comporta meglio è quello formato dalle feature di Mairesse con pre-processing NLoN (accuracy uguale a 1). Per l'Agreeableness, invece, il set più adatto risulta essere quello che include gli n-grammi senza NLoN (accuracy pari a 1). Similmente per il tratto del Neuroticism, la classificazione migliore si consegue con l'ultimo set di feature (accuracy uguale a 1).

Osservando i valori di MAE, si nota come, in media, il tasso di errore più basso (0.196) è raggiunto con il penultimo set di feature. Lo stesso si nota con la metrica di RMSE, dove con il penultimo set di feature si ottiene il valore minore (0.396).

* Best model selection - Task di classificazione binario 2

```{r}
data = c('RObjects/feature_texts_task2.rds',
         'RObjects/feature_texts_nlon_task2.rds',
         'RObjects/feature_texts_task2_ngrams.rds',
         'RObjects/feature_texts_nlon_task2_ngrams.rds')

metrics_df = get_metrics_df(data)

kable(metrics_df[[1]], caption = 'Accuracy con best model selection liblinear task 2')%>%
        kable_styling("striped") %>%
        add_header_above(c(" " = 1, "Accuracy" = 6))

kable(metrics_df[[2]], caption = 'MAE con best model selection liblinear task 2')%>%
        kable_styling("striped") %>%
        add_header_above(c(" " = 1, "MAE" = 6))

kable(metrics_df[[3]], caption = 'RMSE con best model selection liblinear task 2')%>%
        kable_styling("striped") %>%
        add_header_above(c(" " = 1, "RMSE" = 6))
```

Guardando i valori di accuracy ottenuti dalla classificazione, si nota come le accuracy medie coi 4 set di feature siano comprese nell'intervallo tra 0.7 e 0.8. Le prestazioni migliori (accuracy media pari a 0.802) si registrano utilizzando come set di feature quello composto dalle feature Mairesse con n-grammi con pre-processing NLoN. Un valore medio minore è ottenuto usando il set di feature composto dalle feature Mairesse e pre-processing NLoN (accuracy pari a 0.76). Peggiori sono le performance di accuratezza con i due set senza pre-processing NLoN: quello con le sole feature Mairesse raggiunge 0.702 mentre il set con gli n-grammi 0.706.
  
Analizzando le accuracy per singolo tratto di personalità, si osserva come con il set formato dalle feature Mairesse con NLoN si ottengano i risultati migliori in Openness (0.75) e Conscientiousness (1). Con l'ultimo set di feature, composto dalle feature Mairesse con n-grammi con NLoN, si registrano i risultati migliori per i tratti di Extraversion (0.86), Agreeableness (0.89) e Neuroticism (0.89, risultato condiviso con il set formato dalle sole feature Mairesse senza NLoN).

Osservando i valori di MAE, si nota come, in media, il tasso di errore più basso (0.198) è raggiunto con l'ultimo set di feature. Lo stesso si nota per i valori di RMSE medio (0.43).

* Best model selection - Task di classificazione binario 3

```{r}
data = c('RObjects/feature_texts_task3.rds',
         'RObjects/feature_texts_nlon_task3.rds',
         'RObjects/feature_texts_task3_ngrams.rds',
         'RObjects/feature_texts_nlon_task3_ngrams.rds')

metrics_df = get_metrics_df(data)

kable(metrics_df[[1]], caption = 'Accuracy con best model selection liblinear task 3')%>%
        kable_styling("striped") %>%
        add_header_above(c(" " = 1, "Accuracy" = 6))

kable(metrics_df[[2]], caption = 'MAE con best model selection liblinear task 3')%>%
        kable_styling("striped") %>%
        add_header_above(c(" " = 1, "MAE" = 6))

kable(metrics_df[[3]], caption = 'RMSE con best model selection liblinear task 3')%>%
        kable_styling("striped") %>%
        add_header_above(c(" " = 1, "RMSE" = 6))
```

Osservando i valori di accuracy registrati dalla classificazione, si nota come le accuracy medie coi 4 set di feature siano comprese nell'intervallo tra 0.6 e 0.74. Le prestazioni migliori (accuracy media pari a 0.744) si registrano utilizzando come set di feature quello composto dalle feature Mairesse con n-grammi con pre-processing NLoN. Un valore medio minore è ottenuto usando il set di feature composto dalle feature Mairesse con n-grammi senza pre-processing NLoN (accuracy pari a 0.698).  Peggiori sono le performance di accuratezza con i due set senza pre-processing NLoN: entrambi raggiungono un'accuracy media sui cinque tratti uguale a 0.606.

Analizzando le accuracy per singolo tratto di personalità, si osserva come con il set formato dalle feature Mairesse con n-grammi e pre-processing con NLoN si ottengano i risultati migliori per i tratti di Openness (0.85), Conscientiousness (0.69), Extraversion (0.85) e Neuroticism (0.69). Per l'Agreeableness il set più adatto risulta essere quello composto dalle feature Mairesse e dagli n-grammi, senza pre-processing con NLoN (l'accuracy equivale a 0.71).

Osservando i valori di MAE, si nota come, in media, il tasso di errore più basso (0.256) è raggiunto con l'ultimo set di feature. Lo stesso si nota con la metrica di RMSE, dove con l'ultimo set di feature si ottiene il valore minore (0.496).