---
title: "Classificazione con Naive Bayes - Task di classificazione binario 3"
output:
  html_document:
    df_print: paged
---
```{r setup, include=FALSE}
library(caret)
require(SparseM)
library(kableExtra)
options(knitr.table.format = "html")

excluded_predictors <- c('ID')
class <- c('cOPE','cCON','cEXT','cAGR','cNEU')

classification <- function(class_num) {
  excluded_predictors_new <- c(excluded_predictors,class[-class_num])
  d <- dataset[ , !(names(dataset) %in% excluded_predictors_new)]
    
  d <- d[!(d[,class[class_num]]=='n'),]
  d[,class[class_num]] <- factor(d[,class[class_num]])
  
  set.seed(1234)
  trainIndex <- createDataPartition(d[,class[class_num]], p=0.70, list=FALSE)
  data_train <- d[ trainIndex,]
  data_test <- d[-trainIndex,]
    
  x_train <- data_train[, !(names(data_train) %in% class[class_num])]
  y_train <- data_train[,class[class_num]]
  x_test <- data_test[, !(names(data_test) %in% class[class_num])]
  y_test <- data_test[,class[class_num]]
    
  model = train(x_train,y_train,'nb',trControl=trainControl(method='cv',number=10))
    
  NB_Predictions=predict(model$finalModel,x_test)
  cm <- confusionMatrix(NB_Predictions$class,y_test, positive='H')
  
  accuracy <- round(cm$overall[1], digits = 2)
  rmse <- round(RMSE(as.numeric(NB_Predictions$class),as.numeric(y_test)),2)
  mae <- round(MAE(as.numeric(NB_Predictions$class),as.numeric(y_test)),2)
  return(c(mae,rmse,accuracy))
}	

data = c('RObjects/feature_texts_task3.rds',
         'RObjects/feature_texts_nlon_task3.rds',
         'RObjects/feature_texts_task3_ngrams.rds',
         'RObjects/feature_texts_nlon_task3_ngrams.rds')
```

Si riporta di seguito la classificazione effettuata tramite Naive Bayes per il task di classificazione binario 3, secondo il quale sono stati considerati come valori high quelli maggiori della media, e valori low quelli minori della media.

Di conseguenza sono stati eliminati dal dataset i valori "neutral" che non rientravano nè tra gli high nè tra i low, riducendo così la grandezza del dataset (inizialmente composto da 47 data point).

Per quanto riguarda la classificazione, si è diviso il dataset intero in training set (70%) e test set (30%). Si è addestrato il modello sul training set effettuando una 10-fold cross validation. Si è poi sfruttato il modello addestrato per predire i valori del test set, andando a generare la matrice di confusione e le metriche di accuracy, MAE e RMSE.

Il processo si è ripetuto per i quattro diversi insiemi di feature, e i risultati sono mostrati in tre diverse tabelle: la prima riporta i valori di accuracy, la seconda quelli di MAE e l'ultima di RMSE. In ogni tabella le righe rappresentano i set di feature analizzati, mentre le colonne indicano il tratto di personalità valutato, con l'ultima colonna che riporta la media dei risultati per set di feature.

```{r, include=FALSE, warnings=FALSE}
file_num <- 1
dataset <- readRDS(data[file_num])

accuracies <- list()
maes <- list()
rmses <- list()
class_num <- 1
result = classification(class_num)
mae <- result[1]
rmse <- result[2]
accuracy <- result[3]

class_name <- substr(class[class_num], 2, nchar(class[class_num]))
accuracies_df <- data.frame("Feature" = c("Mairesse, no NLoN"), 'temp_name' = as.numeric(accuracy), stringsAsFactors = F)
names(accuracies_df)[names(accuracies_df) == 'temp_name'] <- class_name
accuracies[class_num] <- as.numeric(accuracy)

mae_df <- data.frame("Feature" = c("Mairesse, no NLoN"), 'temp_name' = as.numeric(mae), stringsAsFactors = F)
names(mae_df)[names(mae_df) == 'temp_name'] <- class_name
maes[class_num] <- as.numeric(mae)

rmse_df <- data.frame("Feature" = c("Mairesse, no NLoN"), 'temp_name' = as.numeric(rmse), stringsAsFactors = F)
names(rmse_df)[names(rmse_df) == 'temp_name'] <- class_name
rmses[class_num] <- as.numeric(rmse)

for(class_num in 2:5){
  result = classification(class_num)
  mae <- result[1]
  rmse <- result[2]
  accuracy <- result[3]
  
  class_name <- substr(class[class_num], 2, nchar(class[class_num]))
  
  accuracies_df <- cbind(accuracies_df,'temp_name'=as.numeric(accuracy))
  names(accuracies_df)[names(accuracies_df) == 'temp_name'] <- class_name
  accuracies[class_num] <- as.numeric(accuracy)
  
  mae_df <- cbind(mae_df,'temp_name'=as.numeric(mae))
  names(mae_df)[names(mae_df) == 'temp_name'] <- class_name
  maes[class_num] <- as.numeric(mae)
  
  rmse_df <- cbind(rmse_df,'temp_name'=as.numeric(rmse))
  names(rmse_df)[names(rmse_df) == 'temp_name'] <- class_name
  rmses[class_num] <- as.numeric(rmse)
  }

accuracies_df <- cbind(accuracies_df,'mean'=mean(as.numeric(accuracies)))
mae_df <- cbind(mae_df,'mean'=mean(as.numeric(maes)))
rmse_df <- cbind(rmse_df,'mean'=mean(as.numeric(rmses)))

row_names = c('Mairesse, with NLoN',
              'Mairesse+N-grams, no NLoN',
              'Mairesse+N-grams, with NLoN')
for(file_num in (2:length(data))){
  dataset <- readRDS(data[file_num])
  accuracies <- list()
  maes <- list()
  rmses <- list()
  
  class_num <- 1
  result = classification(class_num)
  mae <- result[1]
  rmse <- result[2]
  accuracy <- result[3]
  
  class_name <- substr(class[class_num], 2, nchar(class[class_num]))
  
  accuracies_df <- rbind(accuracies_df,list(row_names[file_num-1],0,0,0,0,0,0))
  accuracies_df[file_num,class_name] <- as.numeric(accuracy)
  accuracies[class_num] <- as.numeric(accuracy)
  
  mae_df <- rbind(mae_df,list(row_names[file_num-1],0,0,0,0,0,0))
  mae_df[file_num,class_name] <- as.numeric(mae)
  maes[class_num] <- as.numeric(mae)
  
  rmse_df <- rbind(rmse_df,list(row_names[file_num-1],0,0,0,0,0,0))
  rmse_df[file_num,class_name] <- as.numeric(rmse)
  rmses[class_num] <- as.numeric(rmse)
  
  for(class_num in 2:5){
    result = classification(class_num)
    mae <- result[1]
    rmse <- result[2]
    accuracy <- result[3]
    
    class_name <- substr(class[class_num], 2, nchar(class[class_num]))
    
    accuracies_df[file_num,class_name] <- as.numeric(accuracy)
    accuracies[class_num] <- as.numeric(accuracy)
    
    mae_df[file_num,class_name] <- as.numeric(mae)
    maes[class_num] <- as.numeric(mae)
    
    rmse_df[file_num,class_name] <- as.numeric(rmse)
    rmses[class_num] <- as.numeric(rmse)
  }
  accuracies_df[file_num,'mean'] <- mean(as.numeric(accuracies))
  mae_df[file_num,'mean'] <- mean(as.numeric(maes))
  rmse_df[file_num,'mean'] <- mean(as.numeric(rmses))
}
```
 
```{r}
kable(accuracies_df, 
      caption = 'Accuracy')%>%
        kable_styling("striped") %>%
        add_header_above(c(" " = 1,"Accuracy" = 6))
```

Osservando i valori di accuracy ottenuti dalla classificazione, si nota come le prestazioni migliori (accuracy pari a 0.544) si siano raggiunte utilizzando come set di feature quello composto dalle feature Mairesse con n-grammi senza pre-processing NLoN e quello composto dalle feature Mairesse con n-grammi e pre-processing NLoN. Non vi è infatti differenza nei risultati riportati dai questi 2 set di feature per i 5 tratti di personalità (stessi valori di accuracy, MAE e RMSE). Peggiori sono le performance di accuratezza (0.498) con il set di feature Mairesse con NLoN, mentre il valore minore (0.406) è ottenuto con il set di feature Mairesse senza pre-processing NLoN.

Analizzando le accuracy per singolo tratta di personalità, però, si osserva come con il set di feature di Mairesse con NLoN si ottengano i valori maggiori accuracy per i tratti di Openness (0.54), Conscientiousness (0.62) e Agreeableness (0.64) (pari valore si ottiene con i set di feature Mairesse con n-grammi con e senza NLoN). Tuttavia, con questo set di feature l'accuracy per l'Extraversion (0.31) e per Neuroticism (0.38) è la peggiore riportata tra i 4 set di feature (per il Neuroticism si ottiene un valore pari a 0.38 anche con il set composto dalle sole feature Mairesse senza NLoN). Il set con il quale si raggiungono le prestazioni peggiori per singolo tratto è quello composto dalle feature Mairesse senza NLoN (solo per l'Openness l'accuracy è pari a 0.46 come per i set composti dalle feature Mairesse con n-grammi, con e senza NLoN).

```{r}
kable(mae_df, 
      caption = 'MAE')%>%
        kable_styling("striped") %>%
        add_header_above(c(" " = 1,"MAE" = 6))
```

Osservando i valori di MAE, si nota come, in media, il tasso di errore più basso (0.456) è raggiunto con i 2 set di feature composti dalle feature Mairesse con n-grammi, senza NLoN e con NLoN. Con il set di feature Mairesse e pre-processing NLoN il MAE medio sui 5 tratti equivale a 0.502, mentre con il set composto dalle feature Mairesse senza NLoN il MAE è pari a 0.594.

```{r}
kable(rmse_df, 
      caption = 'RMSE')%>%
        kable_styling("striped") %>%
        add_header_above(c(" " = 1,"RMSE" = 6))
```

Riguardo il RMSE il valore minore (0.672) è ottenuto con gli ultimi 2 set di feature, mentre con il set composto dalle feature Mairesse con NLoN il RMSE è uguale a 0.702, e per quello formato dalle feature Mairesse senza NLoN equivale a 0.766.
